{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from pyspark.sql import SparkSession",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "spark = SparkSession.builder.appName('nlp').getOrCreate()",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df = spark.read.csv('SMSSpamCollection',inferSchema=True,sep='\\t')",
      "execution_count": 5,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.show()",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+----+--------------------+\n| _c0|                 _c1|\n+----+--------------------+\n| ham|Go until jurong p...|\n| ham|Ok lar... Joking ...|\n|spam|Free entry in 2 a...|\n| ham|U dun say so earl...|\n| ham|Nah I don't think...|\n|spam|FreeMsg Hey there...|\n| ham|Even my brother i...|\n| ham|As per your reque...|\n|spam|WINNER!! As a val...|\n|spam|Had your mobile 1...|\n| ham|I'm gonna be home...|\n|spam|SIX chances to wi...|\n|spam|URGENT! You have ...|\n| ham|I've been searchi...|\n| ham|I HAVE A DATE ON ...|\n|spam|XXXMobileMovieClu...|\n| ham|Oh k...i'm watchi...|\n| ham|Eh u remember how...|\n| ham|Fine if thats th...|\n|spam|England v Macedon...|\n+----+--------------------+\nonly showing top 20 rows\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df = df.withColumnRenamed('_c0','class').withColumnRenamed('_c1','text')",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from pyspark.sql.functions import length",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df = df.withColumn('length',length(df['text']))",
      "execution_count": 11,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.show()",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+-----+--------------------+------+\n|class|                text|length|\n+-----+--------------------+------+\n|  ham|Go until jurong p...|   111|\n|  ham|Ok lar... Joking ...|    29|\n| spam|Free entry in 2 a...|   155|\n|  ham|U dun say so earl...|    49|\n|  ham|Nah I don't think...|    61|\n| spam|FreeMsg Hey there...|   147|\n|  ham|Even my brother i...|    77|\n|  ham|As per your reque...|   160|\n| spam|WINNER!! As a val...|   157|\n| spam|Had your mobile 1...|   154|\n|  ham|I'm gonna be home...|   109|\n| spam|SIX chances to wi...|   136|\n| spam|URGENT! You have ...|   155|\n|  ham|I've been searchi...|   196|\n|  ham|I HAVE A DATE ON ...|    35|\n| spam|XXXMobileMovieClu...|   149|\n|  ham|Oh k...i'm watchi...|    26|\n|  ham|Eh u remember how...|    81|\n|  ham|Fine if thats th...|    56|\n| spam|England v Macedon...|   155|\n+-----+--------------------+------+\nonly showing top 20 rows\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.groupBy('class').mean().show()",
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+-----+-----------------+\n|class|      avg(length)|\n+-----+-----------------+\n|  ham|71.45431945307645|\n| spam|138.6706827309237|\n+-----+-----------------+\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from pyspark.ml.feature import Tokenizer,StopWordsRemover,CountVectorizer,IDF,StringIndexer",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "tokenizer = Tokenizer(inputCol='text',outputCol='token_text')",
      "execution_count": 16,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "stop_remove = StopWordsRemover(inputCol='token_text',outputCol='stop_token')",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "count_vec = CountVectorizer(inputCol='stop_token',outputCol='count_vec')",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "idf = IDF(inputCol='count_vec',outputCol='tf_idf')",
      "execution_count": 19,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ham_spam_to_numeric = StringIndexer(inputCol='class',outputCol='label')",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from pyspark.ml.feature import VectorAssembler",
      "execution_count": 22,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "final_df = VectorAssembler(inputCols=['tf_idf','label'],outputCol='features')",
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from pyspark.ml.classification import NaiveBayes",
      "execution_count": 25,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "nb = NaiveBayes()",
      "execution_count": 26,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from pyspark.ml import Pipeline",
      "execution_count": 28,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "data_prep_pipeline = Pipeline(stages=[ham_spam_to_numeric,tokenizer,stop_remove,count_vec,idf,final_df])",
      "execution_count": 29,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cleaner = data_prep_pipeline.fit(df)",
      "execution_count": 31,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "clean_data = cleaner.transform(df)",
      "execution_count": 33,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "clean_data.columns",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 36,
          "data": {
            "text/plain": "['class',\n 'text',\n 'length',\n 'label',\n 'token_text',\n 'stop_token',\n 'count_vec',\n 'tf_idf',\n 'features']"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "clean_data = clean_data.select('label','features')",
      "execution_count": 37,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "clean_data.show()",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+-----+--------------------+\n|label|            features|\n+-----+--------------------+\n|  0.0|(13424,[7,11,31,6...|\n|  0.0|(13424,[0,24,297,...|\n|  1.0|(13424,[2,13,19,3...|\n|  0.0|(13424,[0,70,80,1...|\n|  0.0|(13424,[36,134,31...|\n|  1.0|(13424,[10,60,139...|\n|  0.0|(13424,[10,53,103...|\n|  0.0|(13424,[125,184,4...|\n|  1.0|(13424,[1,47,118,...|\n|  1.0|(13424,[0,1,13,27...|\n|  0.0|(13424,[18,43,120...|\n|  1.0|(13424,[8,17,37,8...|\n|  1.0|(13424,[13,30,47,...|\n|  0.0|(13424,[39,96,217...|\n|  0.0|(13424,[552,1697,...|\n|  1.0|(13424,[30,109,11...|\n|  0.0|(13424,[82,214,47...|\n|  0.0|(13424,[0,2,49,13...|\n|  0.0|(13424,[0,74,105,...|\n|  1.0|(13424,[4,30,33,5...|\n+-----+--------------------+\nonly showing top 20 rows\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "train_data,test_data = clean_data.randomSplit([0.7,0.3])",
      "execution_count": 41,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "spam_detector = nb.fit(train_data)",
      "execution_count": 42,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "test_results = spam_detector.transform(test_data)",
      "execution_count": 43,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "test_results.show()",
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+-----+--------------------+--------------------+--------------------+----------+\n|label|            features|       rawPrediction|         probability|prediction|\n+-----+--------------------+--------------------+--------------------+----------+\n|  0.0|(13424,[0,1,2,7,8...|[-658.92467796144...|[1.0,4.1183735455...|       0.0|\n|  0.0|(13424,[0,1,2,13,...|[-511.75752709700...|[1.0,3.3252433026...|       0.0|\n|  0.0|(13424,[0,1,4,50,...|[-696.61945976279...|[1.0,1.1566806583...|       0.0|\n|  0.0|(13424,[0,1,5,15,...|[-834.80182351772...|[1.0,3.3028974184...|       0.0|\n|  0.0|(13424,[0,1,14,31...|[-170.69032650863...|[1.0,7.7593824470...|       0.0|\n|  0.0|(13424,[0,1,17,19...|[-674.52298364345...|[1.0,1.5012215667...|       0.0|\n|  0.0|(13424,[0,1,18,20...|[-734.26979420610...|[1.0,3.8877817053...|       0.0|\n|  0.0|(13424,[0,1,21,27...|[-632.03861018862...|[1.0,8.1786831755...|       0.0|\n|  0.0|(13424,[0,1,24,31...|[-292.58677472712...|[1.0,1.7152016413...|       0.0|\n|  0.0|(13424,[0,1,31,43...|[-277.86777067150...|[1.0,5.3990575584...|       0.0|\n|  0.0|(13424,[0,1,46,17...|[-983.05441534580...|[2.28303886651666...|       1.0|\n|  0.0|(13424,[0,1,72,10...|[-584.99323137014...|[1.0,8.5519255301...|       0.0|\n|  0.0|(13424,[0,1,874],...|[-76.865941575224...|[0.99999998134452...|       0.0|\n|  0.0|(13424,[0,2,3,6,9...|[-2765.7304958126...|[1.0,3.7189734628...|       0.0|\n|  0.0|(13424,[0,2,3,8,2...|[-1382.3225879586...|[1.0,1.0762561271...|       0.0|\n|  0.0|(13424,[0,2,4,5,7...|[-816.94869079989...|[1.0,8.4713694336...|       0.0|\n|  0.0|(13424,[0,2,5,8,4...|[-711.41531009180...|[1.0,1.9947146927...|       0.0|\n|  0.0|(13424,[0,2,8,27,...|[-1222.9004405028...|[1.0,2.9808782559...|       0.0|\n|  0.0|(13424,[0,2,11,14...|[-237.07227236838...|[1.0,2.9272408912...|       0.0|\n|  0.0|(13424,[0,2,11,23...|[-682.13719425197...|[1.0,7.9975625864...|       0.0|\n+-----+--------------------+--------------------+--------------------+----------+\nonly showing top 20 rows\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from pyspark.ml.evaluation import MulticlassClassificationEvaluator",
      "execution_count": 45,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "acc_eval = MulticlassClassificationEvaluator()",
      "execution_count": 46,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "acc = acc_eval.evaluate(test_results)",
      "execution_count": 47,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "print('ACC of NB Model')\nprint(acc)",
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": "ACC of NB Model\n0.9173964513325802\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}