{
  "cells": [
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from pyspark.sql import SparkSession",
      "execution_count": 1,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "spark = SparkSession.builder.appName('nlp').getOrCreate()",
      "execution_count": 2,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from pyspark.ml.feature import Tokenizer,RegexTokenizer\nfrom pyspark.sql.functions import col,udf\nfrom pyspark.sql.types import IntegerType",
      "execution_count": 3,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sentence_df = spark.createDataFrame([\n    (0,'Hi I heard about Spark'),\n    (1,'I wish Java could use case classes'),\n    (2,'logistic,regression,models,are,neat')],\n    ['id','sentence'])",
      "execution_count": 4,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sentence_df.show()",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+---+--------------------+\n| id|            sentence|\n+---+--------------------+\n|  0|Hi I heard about ...|\n|  1|I wish Java could...|\n|  2|logistic,regressi...|\n+---+--------------------+\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Tokenizer"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "tokenizer = Tokenizer(inputCol='sentence',outputCol='words')\nregexTokenizer = RegexTokenizer(inputCol='sentence',outputCol='words',pattern='\\\\W')",
      "execution_count": 6,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "countTokens = udf(lambda words: len(words), IntegerType())",
      "execution_count": 7,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "tokenized = tokenizer.transform(sentence_df)",
      "execution_count": 8,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "tokenized.withColumn('tokens',countTokens(col('words'))).show()",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+---+--------------------+--------------------+------+\n| id|            sentence|               words|tokens|\n+---+--------------------+--------------------+------+\n|  0|Hi I heard about ...|[hi, i, heard, ab...|     5|\n|  1|I wish Java could...|[i, wish, java, c...|     7|\n|  2|logistic,regressi...|[logistic,regress...|     1|\n+---+--------------------+--------------------+------+\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "regexTokenized = regexTokenizer.transform(sentence_df)",
      "execution_count": 10,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "regexTokenized.withColumn('tokens',countTokens(col('words'))).show()",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+---+--------------------+--------------------+------+\n| id|            sentence|               words|tokens|\n+---+--------------------+--------------------+------+\n|  0|Hi I heard about ...|[hi, i, heard, ab...|     5|\n|  1|I wish Java could...|[i, wish, java, c...|     7|\n|  2|logistic,regressi...|[logistic, regres...|     5|\n+---+--------------------+--------------------+------+\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# Stop Words Removal"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from pyspark.ml.feature import StopWordsRemover",
      "execution_count": 12,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sentence_df = spark.createDataFrame([\n    (0,['I','saw','the','red','balloon']),\n    (1,['mary','had','a','little','lamb'])],\n    ['id','raw'])",
      "execution_count": 13,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sentence_df.show()",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+---+--------------------+\n| id|                 raw|\n+---+--------------------+\n|  0|[I, saw, the, red...|\n|  1|[mary, had, a, li...|\n+---+--------------------+\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "remover = StopWordsRemover(inputCol='raw',outputCol='featured')",
      "execution_count": 15,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "remover.transform(sentence_df).show(truncate=False)",
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+---+----------------------------+--------------------+\n|id |raw                         |featured            |\n+---+----------------------------+--------------------+\n|0  |[I, saw, the, red, balloon] |[saw, red, balloon] |\n|1  |[mary, had, a, little, lamb]|[mary, little, lamb]|\n+---+----------------------------+--------------------+\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": "# n-grams"
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from pyspark.ml.feature import NGram",
      "execution_count": 17,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "wordDataFrame = spark.createDataFrame([\n    (0, [\"Hi\", \"I\", \"heard\", \"about\", \"Spark\"]),\n    (1, [\"I\", \"wish\", \"Java\", \"could\", \"use\", \"case\", \"classes\"]),\n    (2, [\"Logistic\", \"regression\", \"models\", \"are\", \"neat\"])], \n    [\"id\", \"words\"])",
      "execution_count": 18,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "wordDataFrame.show(truncate=False)",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+---+------------------------------------------+\n|id |words                                     |\n+---+------------------------------------------+\n|0  |[Hi, I, heard, about, Spark]              |\n|1  |[I, wish, Java, could, use, case, classes]|\n|2  |[Logistic, regression, models, are, neat] |\n+---+------------------------------------------+\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ngram = NGram(n=2,inputCol='words',outputCol='ngrams')",
      "execution_count": 20,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ngramDataFrame = ngram.transform(wordDataFrame)",
      "execution_count": 21,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "ngramDataFrame.select('ngrams').show(truncate=False)",
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+------------------------------------------------------------------+\n|ngrams                                                            |\n+------------------------------------------------------------------+\n|[Hi I, I heard, heard about, about Spark]                         |\n|[I wish, wish Java, Java could, could use, use case, case classes]|\n|[Logistic regression, regression models, models are, are neat]    |\n+------------------------------------------------------------------+\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from pyspark.ml.feature import HashingTF,IDF,Tokenizer",
      "execution_count": 23,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sentenceData = spark.createDataFrame([\n    (0.0,'Hi I heard about Spark'),\n    (0.0,'I wish Java could use case classes'),\n    (1.0,'logistic,regression,models,are,neat')],\n    ['label','sentence'])",
      "execution_count": 24,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "sentenceData.show()",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+-----+--------------------+\n|label|            sentence|\n+-----+--------------------+\n|  0.0|Hi I heard about ...|\n|  0.0|I wish Java could...|\n|  1.0|logistic,regressi...|\n+-----+--------------------+\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "tokenizer = Tokenizer(inputCol='sentence',outputCol='words')",
      "execution_count": 26,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "words_data = tokenizer.transform(sentenceData)",
      "execution_count": 27,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "words_data.show()",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+-----+--------------------+--------------------+\n|label|            sentence|               words|\n+-----+--------------------+--------------------+\n|  0.0|Hi I heard about ...|[hi, i, heard, ab...|\n|  0.0|I wish Java could...|[i, wish, java, c...|\n|  1.0|logistic,regressi...|[logistic,regress...|\n+-----+--------------------+--------------------+\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "hashing_tf = HashingTF(inputCol='words',outputCol='rawFeatures')",
      "execution_count": 29,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "hashed_data = hashing_tf.transform(words_data)",
      "execution_count": 30,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "hashed_data.show(truncate=False)",
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+-----+-----------------------------------+------------------------------------------+--------------------------------------------------------------------------------------+\n|label|sentence                           |words                                     |rawFeatures                                                                           |\n+-----+-----------------------------------+------------------------------------------+--------------------------------------------------------------------------------------+\n|0.0  |Hi I heard about Spark             |[hi, i, heard, about, spark]              |(262144,[24417,49304,73197,91137,234657],[1.0,1.0,1.0,1.0,1.0])                       |\n|0.0  |I wish Java could use case classes |[i, wish, java, could, use, case, classes]|(262144,[20719,24417,55551,116873,147765,162369,192310],[1.0,1.0,1.0,1.0,1.0,1.0,1.0])|\n|1.0  |logistic,regression,models,are,neat|[logistic,regression,models,are,neat]     |(262144,[84234],[1.0])                                                                |\n+-----+-----------------------------------+------------------------------------------+--------------------------------------------------------------------------------------+\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "idf = IDF(inputCol='rawFeatures',outputCol='features')",
      "execution_count": 32,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "idf_model = idf.fit(hashed_data)",
      "execution_count": 33,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "rescaled_data = idf_model.transform(hashed_data)",
      "execution_count": 34,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "rescaled_data.select('label','features').show(truncate=False)",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|label|features                                                                                                                                                                                        |\n+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n|0.0  |(262144,[24417,49304,73197,91137,234657],[0.28768207245178085,0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453])                                                     |\n|0.0  |(262144,[20719,24417,55551,116873,147765,162369,192310],[0.6931471805599453,0.28768207245178085,0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453,0.6931471805599453])|\n|1.0  |(262144,[84234],[0.6931471805599453])                                                                                                                                                           |\n+-----+------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "from pyspark.ml.feature import CountVectorizer",
      "execution_count": 38,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df = spark.createDataFrame([\n    (0,'a b c'.split(' ')),\n    (1,'a b b c a'.split(' '))],\n    ['id','words'])",
      "execution_count": 39,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "df.show()",
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+---+---------------+\n| id|          words|\n+---+---------------+\n|  0|      [a, b, c]|\n|  1|[a, b, b, c, a]|\n+---+---------------+\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "cv = CountVectorizer(inputCol='words',outputCol='features',vocabSize=3,minDF=2.0)",
      "execution_count": 42,
      "outputs": []
    },
    {
      "metadata": {},
      "cell_type": "markdown",
      "source": ""
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "model = cv.fit(df)",
      "execution_count": 43,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "result = model.transform(df)",
      "execution_count": 44,
      "outputs": []
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "result.show(truncate=False)",
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": "+---+---------------+-------------------------+\n|id |words          |features                 |\n+---+---------------+-------------------------+\n|0  |[a, b, c]      |(3,[0,1,2],[1.0,1.0,1.0])|\n|1  |[a, b, b, c, a]|(3,[0,1,2],[2.0,2.0,1.0])|\n+---+---------------+-------------------------+\n\n",
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "trusted": true
      },
      "cell_type": "code",
      "source": "",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python36",
      "display_name": "Python 3.6",
      "language": "python"
    },
    "language_info": {
      "mimetype": "text/x-python",
      "nbconvert_exporter": "python",
      "name": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.6",
      "file_extension": ".py",
      "codemirror_mode": {
        "version": 3,
        "name": "ipython"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}